{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd5d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import functional as F\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b00ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a, b):\n",
    "    return a.dot(b) / (a.dot(a) * b.dot(b)) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bfdaf3",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27a14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'flax-community/papuGaPT2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def tokenize(word):\n",
    "    ids = tokenizer(word, return_tensors='pt')['input_ids'][0]\n",
    "    return [tokenizer.decode(n) for n in ids]\n",
    "\n",
    "emb = model.transformer.wte.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06270c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_free_token_embedding(word):\n",
    "    token_ids = tokenizer.encode(' ' + word)\n",
    "    whole_word_embbeding = np.sum(np.stack([emb[id] for id in token_ids]), axis=0) / len(token_ids)\n",
    "    return whole_word_embbeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e73521",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f68e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_encoder = \"allegro/herbert-base-cased\"\n",
    "tokenizer_encoder = AutoTokenizer.from_pretrained(model_name_encoder)\n",
    "model_encoder = AutoModel.from_pretrained(model_name_encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b7ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_token_embedding(word):\n",
    "    input_ids = tokenizer_encoder(word, return_tensors='pt')['input_ids'].to(device)\n",
    "    output = model_encoder(input_ids=input_ids)\n",
    "    return output.last_hidden_state.detach().cpu().numpy()[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c2867",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e3855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = 'męzczyzna'\n",
    "female = 'kobieta'\n",
    "\n",
    "uncle = 'wujek'\n",
    "aunt = 'ciocia'\n",
    "king = 'król'\n",
    "queen = 'królowa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1186cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = 'pies'\n",
    "cat = 'kot'\n",
    "babydog = 'szczeniak'\n",
    "wolf = 'wilk'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd3f0a",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51ba85",
   "metadata": {},
   "source": [
    "feminine vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e54f8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00035056360659630706 0.134997398412024\n"
     ]
    }
   ],
   "source": [
    "male_emb = get_context_free_token_embedding(male)\n",
    "female_emb = get_context_free_token_embedding(female)\n",
    "feminity = female_emb - male_emb\n",
    "\n",
    "res1 = get_context_free_token_embedding(aunt) - get_context_free_token_embedding(uncle)\n",
    "res2 = get_context_free_token_embedding(queen) - get_context_free_token_embedding(king)\n",
    "\n",
    "print(cos(feminity, res1), cos(feminity, res2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340bbdca",
   "metadata": {},
   "source": [
    "abx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b54bf28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6544517114198857 0.502280773741618\n",
      "0.5424712195440118 0.49661500595562624\n"
     ]
    }
   ],
   "source": [
    "dog_emb = get_context_free_token_embedding(dog)\n",
    "cat_emb = get_context_free_token_embedding(cat)\n",
    "babydog_emb = get_context_free_token_embedding(babydog)\n",
    "wolf_emb = get_context_free_token_embedding(wolf)\n",
    "\n",
    "print(cos(dog_emb, babydog_emb), cos(cat_emb, babydog_emb))\n",
    "print(cos(dog_emb, wolf_emb), cos(cat_emb, wolf_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790f8bf",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508e28d",
   "metadata": {},
   "source": [
    "feminine vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "870a2df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11467732098042435 -0.14195259783483538\n"
     ]
    }
   ],
   "source": [
    "male_emb = get_context_token_embedding(male)\n",
    "female_emb = get_context_token_embedding(female)\n",
    "feminity = female_emb - male_emb\n",
    "\n",
    "temp1 = get_context_token_embedding(aunt) - get_context_token_embedding(uncle)\n",
    "temp2 = get_context_token_embedding(queen) - get_context_token_embedding(king)\n",
    "\n",
    "print(cos(feminity, temp1), cos(feminity, temp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147779c2",
   "metadata": {},
   "source": [
    "abx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f77c33ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8315782639165055 0.8348302009099379\n",
      "0.9753929077482025 0.9832040527884389\n"
     ]
    }
   ],
   "source": [
    "dog_emb = get_context_token_embedding(dog)\n",
    "cat_emb = get_context_token_embedding(cat)\n",
    "babygod_emb = get_context_token_embedding(babydog)\n",
    "wolf_emb = get_context_token_embedding(wolf)\n",
    "\n",
    "print(cos(dog_emb, babygod_emb), cos(cat_emb, babygod_emb))\n",
    "print(cos(dog_emb, wolf_emb), cos(cat_emb, wolf_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
