{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd5d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import functional as F\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b00ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a, b):\n",
    "    return a.dot(b) / (a.dot(a) * b.dot(b)) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bfdaf3",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27a14fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f39dec07d34588be478feb90848c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/208 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c13f08cada41e1863c4c006e9d83bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/888k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4feb737f26447a6be5a304b35587177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/547k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e6c340d000467d8edc1942a1ba788a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.54M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37e0217e5524055a9d6348bb37b6a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615abb4a2fa34a35977e42e127be7402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'flax-community/papuGaPT2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "def tokenize(word):\n",
    "    ids = tokenizer(word, return_tensors='pt')['input_ids'][0]\n",
    "    return [tokenizer.decode(n) for n in ids]\n",
    "\n",
    "emb = model.transformer.wte.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06270c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_free_token_embedding(word):\n",
    "    token_ids = tokenizer.encode(' ' + word)\n",
    "    emb[token_ids[0]] *= 3\n",
    "    whole_word_embbeding = np.sum(np.stack([emb[id] for id in token_ids]), axis=0) / len(token_ids)\n",
    "    return whole_word_embbeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e73521",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f68e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_encoder = \"allegro/herbert-base-cased\"\n",
    "tokenizer_encoder = AutoTokenizer.from_pretrained(model_name_encoder)\n",
    "model_encoder = AutoModel.from_pretrained(model_name_encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b7ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_token_embedding(word):\n",
    "    input_ids = tokenizer_encoder(word, return_tensors='pt')['input_ids'].to(device)\n",
    "    output = model_encoder(input_ids=input_ids)\n",
    "    return output.last_hidden_state.detach().cpu().numpy()[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf641a",
   "metadata": {},
   "source": [
    "### spoil funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f5a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spoil(word):\n",
    "    replacements = {'ł': 'l', 'ą': 'a', 'ć': 'c', 'ę': 'e', 'ń': 'n', 'ó': 'o', 'ś': 's', 'ź': 'z', 'ż': 'z'}\n",
    "    new_word = ''.join(replacements.get(c, c) for c in word)\n",
    "    if new_word != word:\n",
    "        idx = random.randrange(0, len(new_word) - 1)\n",
    "        temp = list(new_word)\n",
    "        temp[idx], temp[idx + 1] = temp[idx + 1], temp[idx]\n",
    "        new_word = ''.join(temp)\n",
    "    return new_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c2867",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5a2ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clusters_txt = '''piśmiennicze: pisak flamaster ołówek długopis pióro\n",
    "małe_ssaki: mysz szczur chomik łasica kuna bóbr\n",
    "okręty: niszczyciel lotniskowiec trałowiec krążownik pancernik fregata korweta\n",
    "lekarze: lekarz pediatra ginekolog kardiolog internista geriatra\n",
    "zupy: rosół żurek barszcz\n",
    "uczucia: miłość przyjaźń nienawiść gniew smutek radość strach\n",
    "działy_matematyki: algebra analiza topologia logika geometria \n",
    "budynki_sakralne: kościół bazylika kaplica katedra świątynia synagoga zbór\n",
    "stopień_wojskowy: chorąży podporucznik porucznik kapitan major pułkownik generał podpułkownik\n",
    "grzyby_jadalne: pieczarka borowik gąska kurka boczniak kania\n",
    "prądy_filozoficzne: empiryzm stoicyzm racjonalizm egzystencjalizm marksizm romantyzm\n",
    "religie: chrześcijaństwo buddyzm islam prawosławie protestantyzm kalwinizm luteranizm judaizm\n",
    "dzieła_muzyczne: sonata synfonia koncert preludium fuga suita\n",
    "cyfry: jedynka dwójka trójka czwórka piątka szóstka siódemka ósemka dziewiątka\n",
    "owady: ważka biedronka żuk mrówka mucha osa pszczoła chrząszcz\n",
    "broń_biała: miecz topór sztylet nóż siekiera\n",
    "broń_palna: karabin pistolet rewolwer fuzja strzelba\n",
    "komputery: komputer laptop kalkulator notebook\n",
    "kolory: biel żółć czerwień błękit zieleń brąz czerń\n",
    "duchowny: wikary biskup ksiądz proboszcz rabin pop arcybiskup kardynał pastor\n",
    "ryby: karp śledź łosoś dorsz okoń sandacz szczupak płotka\n",
    "napoje_mleczne: jogurt kefir maślanka\n",
    "czynności_sportowe: bieganie skakanie pływanie maszerowanie marsz trucht\n",
    "ubranie:  garnitur smoking frak żakiet marynarka koszula bluzka sweter sweterek sukienka kamizelka spódnica spodnie\n",
    "mebel: krzesło fotel kanapa łóżko wersalka sofa stół stolik ława\n",
    "przestępca: morderca zabójca gwałciciel złodziej bandyta kieszonkowiec łajdak łobuz\n",
    "mięso_wędliny: wieprzowina wołowina baranina cielęcina boczek baleron kiełbasa szynka schab karkówka dziczyzna\n",
    "drzewo: dąb klon wiąz jesion świerk sosna modrzew platan buk cis jawor jarzębina akacja\n",
    "źródło_światła: lampa latarka lampka żyrandol żarówka reflektor latarnia lampka\n",
    "organ: wątroba płuco serce trzustka żołądek nerka macica jajowód nasieniowód prostata śledziona\n",
    "oddziały: kompania pluton batalion brygada armia dywizja pułk\n",
    "napój_alkoholowy: piwo wino wódka dżin nalewka bimber wiśniówka cydr koniak wiśniówka\n",
    "kot_drapieżny: puma pantera lampart tygrys lew ryś żbik gepard jaguar\n",
    "metal: żelazo złoto srebro miedź nikiel cyna cynk potas platyna chrom glin aluminium\n",
    "samolot: samolot odrzutowiec awionetka bombowiec myśliwiec samolocik helikopter śmigłowiec\n",
    "owoc: jabłko gruszka śliwka brzoskwinia cytryna pomarańcza grejpfrut porzeczka nektaryna\n",
    "pościel: poduszka prześcieradło kołdra kołderka poduszeczka pierzyna koc kocyk pled\n",
    "agd: lodówka kuchenka pralka zmywarka mikser sokowirówka piec piecyk piekarnik'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe11883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_embedings_file.txt_a_nospoil.txt', \"w\") as f1, open('word_embedings_file_b_nospoil.txt', 'w') as f2, open('word_embedings_file_a_spoil.txt', 'w') as f3, open('word_embedings_file_b_spoil.txt', 'w') as f4:\n",
    "    for line in clusters_txt.split('\\n'):\n",
    "        words = line.split(':')[1].split()\n",
    "        for word in words:\n",
    "            embedding_a_nospoil = get_context_free_token_embedding(word)\n",
    "            embedding_b_nospoil = get_context_token_embedding(word)\n",
    "            embedding_a_spoil = get_context_free_token_embedding(spoil(word))\n",
    "            embedding_b_spoil = get_context_token_embedding(spoil(word))\n",
    "            f1.write(f\"{word} \" + \" \".join(map(str, embedding_a_nospoil)) + \"\\n\")\n",
    "            f2.write(f\"{word} \" + \" \".join(map(str, embedding_b_nospoil)) + \"\\n\")\n",
    "            f3.write(f\"{word} \" + \" \".join(map(str, embedding_a_spoil)) + \"\\n\")\n",
    "            f4.write(f\"{word} \" + \" \".join(map(str, embedding_b_spoil)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm word_embedings_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e9a29af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "# !export TOKENIZERS_PARALLELISM=true\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "!echo $TOKENIZERS_PARALLELISM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3725e",
   "metadata": {},
   "source": [
    "### a) nospoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5b4e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEMS: 0.0\n",
      "Start\n",
      "TOTAL SCORE: 0.716038\n"
     ]
    }
   ],
   "source": [
    "!cp word_embedings_file_a_nospoil.txt word_embedings_file.txt\n",
    "!python3 word_emb_evaluation.py\n",
    "!rm word_embedings_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bed07",
   "metadata": {},
   "source": [
    "### b) nospoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00f80ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEMS: 0.0\n",
      "Start\n",
      "TOTAL SCORE: 0.593276\n"
     ]
    }
   ],
   "source": [
    "!cp word_embedings_file_b_nospoil.txt word_embedings_file.txt\n",
    "!python3 word_emb_evaluation.py\n",
    "!rm word_embedings_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630f964",
   "metadata": {},
   "source": [
    "### a) spoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff53c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEMS: 0.0\n",
      "Start\n",
      "TOTAL SCORE: 0.603584\n"
     ]
    }
   ],
   "source": [
    "!cp word_embedings_file_a_spoil.txt word_embedings_file.txt\n",
    "!python3 word_emb_evaluation.py\n",
    "!rm word_embedings_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a9b93",
   "metadata": {},
   "source": [
    "### b) spoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57868a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBLEMS: 0.0\n",
      "Start\n",
      "TOTAL SCORE: 0.548334\n"
     ]
    }
   ],
   "source": [
    "!cp word_embedings_file_b_spoil.txt word_embedings_file.txt\n",
    "!python3 word_emb_evaluation.py\n",
    "!rm word_embedings_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9dfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
