{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zagadki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp\n",
    "Zagadki od wieków fascynują ludzi, pobudzając ich umysły do kreatywnego i logicznego myślenia. Od prostych łamigłówek po głębokie zagadki filozoficzne, stanowią one nie tylko formę rozrywki, ale również sztukę rozumienia języka i logicznego wnioskowania. W tym zadaniu będziesz rozwiązywał/a zagadki, polegające na odgadnięciu słowa na podstawie opisu. Wszystkie zagadki wymyślił ChatGPT (ale nie powiemy, która dokładnie wersja i w jaki sposób zachęcona), stąd niektóre mogą być trochę dziwne... Szacujemy, że ludzie są w stanie rozwiązać poprawnie trochę ponad 60% z nich. A jak dobry będzie Twój program?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie\n",
    "Napisz funckję `answer_riddle` która rozwiąże podaną na wejściu zagadkę. Rozwiązaniem jest zawsze jedno słowo. Przykładowe zagadki:\n",
    "\n",
    "- **zagadka:** kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem <br>\n",
    "  **odpowiedź:** pasażerka\n",
    "- **zagadka:** emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu<br>\n",
    "  **odpowiedź:** miłość\n",
    "\n",
    "\n",
    "Naszym kryterium będzie `odwrócona średnia harmoniczna` ([Mean Reciprocal Rank](https://en.wikipedia.org/wiki/Mean_reciprocal_rank)), która działa w następujący sposób: <br>\n",
    "Jeżeli na zwróconej przez Twoją funkcję liście znajdzie się prawidłowa odpowiedź, otrzymasz wówczas punkty: dokładnie $\\frac{1}{k}$ punktów, gdzie $k$ jest pozycją słowa na liście. W szczególności, jeżeli Twój program zgadnie słowo (czyli umieści je na pierwszej pozycji), to otrzymasz 1 punkt. Ostatecznym kryterium jest uśredniona liczba punktów ze wszystkich zagadek.\n",
    "\n",
    "Powyższe kryterium jest zaimplementowane poniżej przez nas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ograniczenia\n",
    "- Twoje finalne rozwiązanie będzie testowane w środowisku **bez** GPU.\n",
    "- Twoja funkcja powinna działać na tyle szybko, aby program był w stanie udzielić odpowiedzi na 100 zagadek w maksymalnie 2 minuty bez użycia GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane\n",
    "Dane dostępne dla Ciebie w tym zadaniu to:\n",
    "* `zagadki_do_testow_clean.txt` - około 2000 przykładowych zagadek\n",
    "* `plwiktionary_definitions_clean.txt` -  plik z definicjami słów wziętymi z [pl.wiktionary.org](https://pl.wiktionary.org/wiki/pl). Z wszystkich definicji z pl.wiktionary.org wzięliśmy definicje 8094 najbardziej popularnych rzeczowników (częstości liczone zgodnie z korpusem https://2018.poleval.pl/index.php/tasks#task3). Uwaga: poprawne rozwiązanie każdej zagadki znajduje się w tym pliku!\n",
    "\n",
    "* `superbazy_clean.txt` - formy bazowe polskich słów, przygotowane na podstawie projektu https://github.com/morfologik/polimorfologik\n",
    "\n",
    "* Wektory osadzeń słów bazowych, wytrenowane modelem Word2Vec z biblioteki Gensim, na korpusie PolEval 2018 Task3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uwagi i wskazówki\n",
    "- Dla każdej zagadki, Twoja funkcja powinna zwrócić listę słów (co najwyżej 20), w kolejności od najbardziej (wg Twojego programu) prawdopodobnej odpowiedzi na zagadkę, do najmniej.\n",
    "- Twoje rozwiazanie bedzie testowane bez dostepu do internetu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pliki Zgłoszeniowe\n",
    "Tylko ten notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja\n",
    "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` będziesz upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających. \n",
    "\n",
    "Za to zadanie możesz zdobyć pomiędzy 0 i 1.5 punktu. Zdobędziesz 0 punktów jeśli wartość kryterium `mean reciprocal rank` na zbiorze testowym wyniesie poniżej 0.02, a 1.5 punktu jeśli wyniesie powyżej 0.3. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością kryterium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kod startowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "FINAL_EVALUATION_MODE = False\n",
    "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
    "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as tokenize\n",
    "from collections import defaultdict as dd\n",
    "import math\n",
    "from gensim.models import Word2Vec\n",
    "import gdown\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# ZMIENIOINE\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.nn import functional as F\n",
    "from transformers import logging\n",
    "from pandas import Series\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.set_verbosity_error()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "path_to_data = './data/'\n",
    "\n",
    "bases = {}\n",
    "# Dictionary mapping words to their base words\n",
    "all_word_definitions = dd(list)\n",
    "# Dictionary containing all base words inverse document frequency\n",
    "base_idf = dd(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "def get_word_base(word):\n",
    "    global bases\n",
    "    word = word.lower()\n",
    "    ret = bases.get(word)\n",
    "    if ret:\n",
    "        return ret\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/patryk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    if not os.path.exists(f\"{path_to_data}/zagadki/w2v_polish_lemmas.model\") \\\n",
    "        or not os.path.exists(f\"{path_to_data}/zagadki/w2v_polish_lemmas.model.syn1neg.npy\") \\\n",
    "        or not os.path.exists(f\"{path_to_data}/zagadki/w2v_polish_lemmas.model.wv.vectors.npy\"):\n",
    "            gdown.download_folder(url=\"https://drive.google.com/drive/folders/1P72og_ORfL3Ojf27n-g06DT0ENduPy8C?usp=sharing\", output=f\"./{path_to_data}\")\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tworzenie bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "for x in open(f'{path_to_data}/zagadki/superbazy_clean.txt'):\n",
    "    word,base = x.lower().split()\n",
    "    bases[word] = base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ladowanie modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZMIENIONE\n",
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "model_word2vec = Word2Vec.load(f'{path_to_data}/zagadki/w2v_polish_lemmas.model')\n",
    "\n",
    "model_name_pauga = 'flax-community/papuGaPT2'\n",
    "tokenizer_papuga = AutoTokenizer.from_pretrained(model_name_pauga)\n",
    "model_papuga = AutoModelForCausalLM.from_pretrained(model_name_pauga).to(device)\n",
    "emb_papuga = model_papuga.transformer.wte.weight.detach().cpu().numpy()\n",
    "del model_papuga\n",
    "\n",
    "# model_name_polka = 'eryk-mazus/polka-1.1b'\n",
    "# tokenizer_polka = AutoTokenizer.from_pretrained(model_name_polka)\n",
    "# model_polka = AutoModelForCausalLM.from_pretrained(model_name_polka).to(device)\n",
    "\n",
    "model_name_herbert = \"allegro/herbert-base-cased\"\n",
    "tokenizer_herbert = AutoTokenizer.from_pretrained(model_name_herbert)\n",
    "model_herbert = AutoModel.from_pretrained(model_name_herbert).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tworzenie all_word_definitions i base_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZMIENONE\n",
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "punctuation = {'!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '``', \"''\"}\n",
    "for x in open(f'{path_to_data}/zagadki/plwiktionary_definitions_clean.txt'):\n",
    "    word, definition = x.split('###')\n",
    "    L = word.split()\n",
    "    if len(L) == 1:\n",
    "        word = L[0]\n",
    "        definition = list(filter(lambda x : x not in punctuation, tokenize(definition.lower()))) # tutaj byl set\n",
    "        if len(definition) == 0: continue\n",
    "        all_word_definitions[word].append(definition)\n",
    "        for word in set(definition):\n",
    "            base_idf[get_word_base(word)] += 1\n",
    "\n",
    "\n",
    "for base in base_idf:\n",
    "    base_idf[base] = -math.log(base_idf[base] / len(all_word_definitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18259.000000\n",
       "mean         8.098898\n",
       "std          1.130758\n",
       "min          0.785740\n",
       "25%          7.611471\n",
       "50%          8.304619\n",
       "75%          8.997766\n",
       "max          8.997766\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series(base_idf).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tworzenie answers i queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "answers = []\n",
    "queries = []\n",
    "\n",
    "with open(f'{path_to_data}/zagadki/zagadki_do_testow_clean.txt') as file:\n",
    "    for line in file:\n",
    "        line = line.replace(';;', '').split()                  \n",
    "        answers.append(line[0])\n",
    "        queries.append(tokenize(' '.join(line[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rękopiśmienny',\n",
       " 'tekst',\n",
       " 'lub',\n",
       " 'dokument',\n",
       " ',',\n",
       " 'niepublikowany',\n",
       " 'drukiem',\n",
       " '.']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kod z kryteriami oceniającymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "def mean_reciprocal_rank(real_answers, computed_answers, K=20):\n",
    "    positions = []\n",
    "\n",
    "    for real_answer, computed_answer in zip(real_answers, computed_answers):\n",
    "        if real_answer in computed_answer[:K]:\n",
    "            pos = computed_answer.index(real_answer) + 1\n",
    "            positions.append(1/pos)\n",
    "    \n",
    "    mrr = sum(positions) / len(real_answers)\n",
    "    print ('Mean Reciprocal Rank =', mrr)\n",
    "    \n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twoje rozwiązanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To jest jedyna sekcja, w której musisz coś zrobić."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a, b):\n",
    "    return a.dot(b) / (a.dot(a) * b.dot(b)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word2vec_embedding(word):\n",
    "#     return model_word2vec.wv[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAPUGA i IDF\n",
    "#### tworzenie all_ward_embeddings - PAPUGA i IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_embedding(word):\n",
    "    token_ids = tokenizer_papuga.encode(' ' + word)\n",
    "    # emb_papuga[token_ids[0]] *= 3.0\n",
    "    whole_word_embbeding = np.sum(np.stack([emb_papuga[id] for id in token_ids]), axis=0)\n",
    "    # whole_word_embbeding = np.sum(np.stack([emb_papuga[id] for id in token_ids]), axis=0) / len(token_ids)\n",
    "    return whole_word_embbeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8085 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8085/8085 [00:14<00:00, 543.43it/s]\n",
      "100%|██████████| 1700/1700 [00:02<00:00, 606.24it/s]\n"
     ]
    }
   ],
   "source": [
    "all_word_definitions_embeddings = dd(list)\n",
    "\n",
    "for word in tqdm(all_word_definitions, total=len(all_word_definitions)):\n",
    "    for definition in all_word_definitions[word]:\n",
    "        definition = list(definition)\n",
    "        first_w_in_definition = definition[0]\n",
    "        base = get_word_base(first_w_in_definition)\n",
    "        res_embbeding = decoder_embedding(first_w_in_definition) * -base_idf[get_word_base(base)]\n",
    "        # res_embbeding = decoder_embedding(first_w_in_definition)\n",
    "        for w in definition[1:]:\n",
    "            base = get_word_base(w)\n",
    "            res_embbeding += decoder_embedding(w) * -base_idf[base]\n",
    "            # res_embbeding += decoder_embedding(w)\n",
    "        all_word_definitions_embeddings[word].append(res_embbeding)\n",
    "\n",
    "for query, answer in tqdm(zip(queries[293:], answers[293:]), total=len(queries[293:])):\n",
    "    guery = list(filter(lambda x : x not in punctuation, query)) # tutaj byl set\n",
    "    first_w_in_definition = query[0]\n",
    "    base = get_word_base(first_w_in_definition)\n",
    "    res_embbeding = decoder_embedding(first_w_in_definition) * -base_idf[get_word_base(base)]\n",
    "    # res_embbeding = decoder_embedding(first_w_in_definition)\n",
    "    for w in query[1:]:\n",
    "        base = get_word_base(w)\n",
    "        res_embbeding += decoder_embedding(w) * -base_idf[base]\n",
    "        # res_embbeding += decoder_embedding(w)\n",
    "    all_word_definitions_embeddings[answer].append(res_embbeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_riddle(riddle, K):\n",
    "    # papuga & idf & earest neighbor word2vec\n",
    "    riddle = list(filter(lambda x: x not in punctuation, riddle))\n",
    "    res_embbeding = decoder_embedding(riddle[0]) * -base_idf[get_word_base(riddle[0])]\n",
    "    # res_embbeding = decoder_embedding(riddle[0])\n",
    "    for word in riddle[1:]:\n",
    "        res_embbeding += decoder_embedding(word) * -base_idf[get_word_base(word)]\n",
    "        # res_embbeding += decoder_embedding(word)\n",
    "    \n",
    "    closest_words = []\n",
    "    for word, embeddings in all_word_definitions_embeddings.items():\n",
    "        for emb in embeddings:\n",
    "            # distance = np.linalg.norm(res_embbeding - emb)\n",
    "            distance = cos(res_embbeding, emb)\n",
    "            closest_words.append((distance, word))\n",
    "    \n",
    "    closest_words = sorted(closest_words, key=lambda x: x[0])\n",
    "    return [word for _, word in closest_words[-K:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HERBERT\n",
    "#### tworzenie all_word_definitions_embeddings - HERBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_embedding(L):\n",
    "    txt = ' '.join(L)\n",
    "    input_ids = tokenizer_herbert(txt, return_tensors='pt')['input_ids'].to(device)\n",
    "    output = model_herbert(input_ids=input_ids)\n",
    "    return output.last_hidden_state.detach().cpu().numpy()[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8085/8085 [05:23<00:00, 25.00it/s]\n",
      "100%|██████████| 1700/1700 [00:23<00:00, 71.46it/s]\n"
     ]
    }
   ],
   "source": [
    "all_word_definitions_embeddings = dd(list)\n",
    "\n",
    "for word in tqdm(all_word_definitions):\n",
    "    for definition in all_word_definitions[word]:\n",
    "        definition = list(filter(lambda x: base_idf[x] > 2.9, definition))\n",
    "        def_embbeding = encoder_embedding(definition)\n",
    "        all_word_definitions_embeddings[word].append(def_embbeding)\n",
    "        \n",
    "for query, answer in tqdm(zip(queries[293:], answers[293:]), total=len(queries[293:])):\n",
    "    guery = list(filter(lambda x : x not in punctuation and base_idf[x] > 2.9, query)) # tutaj byl set\n",
    "    query_embbeding = encoder_embedding(query)\n",
    "    all_word_definitions_embeddings[answer].append(query_embbeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_riddle(riddle, K):\n",
    "    riddle = list(filter(lambda x: x not in punctuation and base_idf[x] > 2.9, riddle))\n",
    "    riddle_embbeding = encoder_embedding(riddle)\n",
    "\n",
    "    closest_words = []\n",
    "    for word, embeddings in all_word_definitions_embeddings.items():\n",
    "        for emb in embeddings:\n",
    "            # distance = np.linalg.norm(res_embbeding - emb)\n",
    "            distance = cos(riddle_embbeding, emb)\n",
    "            closest_words.append((distance, word))\n",
    "    \n",
    "    closest_words = sorted(closest_words, key=lambda x: x[0])\n",
    "    return [word for _, word in closest_words[-K:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ewaluacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy kod będzie służył ewaluacji rozwiązania. Po wysłaniu rozwiązania do nas zostanie wykonana funkcja `evaluate_algorithm(score_function, queries, answers, K)`, t.j. prawie identyczny kod jak niżej będzie się uruchamiał na katalogu danych `test_data` dostępnym tylko dla sprawdzających zadania.\n",
    "\n",
    "Upewnij się przed wysłaniem, że cały notebook wykonuje się od początku do końca bez błędów i bez ingerencji użytkownika po wykonaniu polecenia `Run All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "def evaluate_algorithm(score_function, queries, answers, K):\n",
    "    computed_answers = []\n",
    "    for query in tqdm(queries, desc=\"queries answered\"):\n",
    "        computed_answers.append(score_function(set(query), K=K))\n",
    "    score = mean_reciprocal_rank(answers, computed_answers, K=K)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "queries answered: 100%|██████████| 293/293 [00:59<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank = 0.020161534304620136\n",
      "Score: 0.020161534304620136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    PART_OF_DATA = 293\n",
    "    K = 20\n",
    "    valid_queries = queries[:PART_OF_DATA]\n",
    "    valid_answers = answers[:PART_OF_DATA]\n",
    "    score = evaluate_algorithm(answer_riddle, valid_queries, valid_answers, K=K)\n",
    "    print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " herbert \\\n",
    " queries answered: 100%|██████████| 293/293 [01:04<00:00,  4.51it/s] \\\n",
    " Mean Reciprocal Rank = 0.0036328821908762523 \\\n",
    "Score: 0.0036328821908762523 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "herbert dla idf > 2.9 \\\n",
    "queries answered: 100%|██████████| 293/293 [01:04<00:00,  4.51it/s] \\\n",
    "Mean Reciprocal Rank = 0.0017245330234689801 \\\n",
    "Score: 0.0017245330234689801\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "papgua suma embedow pojedyczych wyrazow \\\n",
    "queries answered: 100%|██████████| 293/293 [01:01<00:00,  4.80it/s] \\\n",
    "Mean Reciprocal Rank = 0.018473519372329588 \\\n",
    "Score: 0.018473519372329588\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "papuga suma ebedow slow wazona  -idf \\\n",
    "queries answered: 100%|██████████| 293/293 [01:01<00:00,  4.74it/s] \\\n",
    "Mean Reciprocal Rank = 0.020161534304620136 \\\n",
    "Score: 0.020161534304620136\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
